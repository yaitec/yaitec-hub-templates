{
  "id": "619614a9-01dd-4346-bdf9-dcc699955899",
  "data": {
    "nodes": [
      {
        "id": "MergeDataComponent-DPEsw",
        "type": "genericNode",
        "position": {
          "x": -764.6327290385755,
          "y": 340.56634352054476
        },
        "data": {
          "type": "MergeDataComponent",
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "A list of Data inputs objects to be merged.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema import Data\n\n\nclass MergeDataComponent(Component):\n    \"\"\"\n    MergeDataComponent is responsible for combining multiple Data objects into a unified list of Data objects.\n    It ensures that all keys across the input Data objects are present in each merged Data object.\n    Missing keys are filled with empty strings to maintain consistency.\n    \"\"\"\n\n    display_name = \"Merge Data\"\n    description = (\n        \"Combines multiple Data objects into a unified list, ensuring all keys are present in each Data object.\"\n    )\n    icon = \"merge\"\n\n    inputs = [\n        DataInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            is_list=True,\n            info=\"A list of Data inputs objects to be merged.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Merged Data\",\n            name=\"merged_data\",\n            method=\"merge_data\",\n        ),\n    ]\n\n    def merge_data(self) -> list[Data]:\n        \"\"\"\n        Merges multiple Data objects into a single list of Data objects.\n        Ensures that all keys from the input Data objects are present in each merged Data object.\n        Missing keys are filled with empty strings.\n\n        Returns:\n            List[Data]: A list of merged Data objects with consistent keys.\n        \"\"\"\n        logger.info(\"Initiating the data merging process.\")\n\n        try:\n            data_inputs: list[Data] = self.data_inputs\n            logger.debug(f\"Received {len(data_inputs)} data input(s) for merging.\")\n\n            if not data_inputs:\n                logger.warning(\"No data inputs provided. Returning an empty list.\")\n                return []\n\n            # Collect all unique keys from all Data objects\n            all_keys: set[str] = set()\n            for idx, data_input in enumerate(data_inputs):\n                if not isinstance(data_input, Data):\n                    error_message = f\"Data input at index {idx} is not of type Data.\"\n                    logger.error(error_message)\n                    type_error_message = (\n                        \"All items in data_inputs must be of type Data. \" f\"Item at index {idx} is {type(data_input)}\"\n                    )\n                    raise TypeError(type_error_message)\n                all_keys.update(data_input.data.keys())\n            logger.debug(f\"Collected {len(all_keys)} unique key(s) from input data.\")\n\n            # Create new list of Data objects with missing keys filled with empty strings\n            merged_data_list = []\n            for idx, data_input in enumerate(data_inputs):\n                merged_data_dict = {}\n\n                for key in all_keys:\n                    # Use the existing value if the key exists, otherwise use an empty string\n                    value = data_input.data.get(key, \"\")\n                    if key not in data_input.data:\n                        log_message = f\"Key '{key}' missing in data input at index {idx}. \" \"Assigning empty string.\"\n                        logger.debug(log_message)\n                    merged_data_dict[key] = value\n\n                merged_data = Data(\n                    text_key=data_input.text_key, data=merged_data_dict, default_value=data_input.default_value\n                )\n                merged_data_list.append(merged_data)\n                logger.debug(f\"Merged Data object created for input at index {idx}.\")\n\n            logger.info(\"Data merging process completed successfully.\")\n            return merged_data_list\n\n        except Exception as e:\n            logger.exception(\"An error occurred during the data merging process.\")\n            raise e\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Combines multiple Data objects into a unified list, ensuring all keys are present in each Data object.",
            "icon": "merge",
            "base_classes": [
              "Data"
            ],
            "display_name": "Merge Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "merged_data",
                "display_name": "Merged Data",
                "method": "merge_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "MergeDataComponent-DPEsw"
        },
        "selected": false,
        "width": 320,
        "height": 235,
        "positionAbsolute": {
          "x": -764.6327290385755,
          "y": 340.56634352054476
        },
        "dragging": false
      },
      {
        "id": "File-JLkjD",
        "type": "genericNode",
        "position": {
          "x": -1690.986305115724,
          "y": 346.02648971374686
        },
        "data": {
          "type": "File",
          "node": {
            "template": {
              "_type": "Component",
              "path": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "zip"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "",
                "display_name": "Path",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx, zip",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pathlib import Path\nfrom tempfile import NamedTemporaryFile\nfrom zipfile import ZipFile, is_zipfile\n\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, FileInput, IntInput, Output\nfrom langflow.schema import Data\n\n\nclass FileComponent(Component):\n    \"\"\"Handles loading of individual or zipped text files.\n\n    Processes multiple valid files within a zip archive if provided.\n\n    Attributes:\n        display_name: Display name of the component.\n        description: Brief component description.\n        icon: Icon to represent the component.\n        name: Identifier for the component.\n        inputs: Inputs required by the component.\n        outputs: Output of the component after processing files.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Load a file to be used in your project.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=[*TEXT_FILE_TYPES, \"zip\"],\n            info=f\"Supported file types: {', '.join([*TEXT_FILE_TYPES, 'zip'])}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, parallel processing will be enabled for zip files.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Multithreading Concurrency\",\n            advanced=True,\n            info=\"The maximum number of workers to use, if concurrency is enabled\",\n            value=4,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"Data\", name=\"data\", method=\"load_file\")]\n\n    def load_file(self) -> Data:\n        \"\"\"Load and parse file(s) from a zip archive.\n\n        Raises:\n            ValueError: If no file is uploaded or file path is invalid.\n\n        Returns:\n            Data: Parsed data from file(s).\n        \"\"\"\n        # Check if the file path is provided\n        if not self.path:\n            self.log(\"File path is missing.\")\n            msg = \"Please upload a file for processing.\"\n\n            raise ValueError(msg)\n\n        resolved_path = Path(self.resolve_path(self.path))\n        try:\n            # Check if the file is a zip archive\n            if is_zipfile(resolved_path):\n                self.log(f\"Processing zip file: {resolved_path.name}.\")\n\n                return self._process_zip_file(\n                    resolved_path,\n                    silent_errors=self.silent_errors,\n                    parallel=self.use_multithreading,\n                )\n\n            self.log(f\"Processing single file: {resolved_path.name}.\")\n\n            return self._process_single_file(resolved_path, silent_errors=self.silent_errors)\n        except FileNotFoundError:\n            self.log(f\"File not found: {resolved_path.name}.\")\n\n            raise\n\n    def _process_zip_file(self, zip_path: Path, *, silent_errors: bool = False, parallel: bool = False) -> Data:\n        \"\"\"Process text files within a zip archive.\n\n        Args:\n            zip_path: Path to the zip file.\n            silent_errors: Suppresses errors if True.\n            parallel: Enables parallel processing if True.\n\n        Returns:\n            list[Data]: Combined data from all valid files.\n\n        Raises:\n            ValueError: If no valid files found in the archive.\n        \"\"\"\n        data: list[Data] = []\n        with ZipFile(zip_path, \"r\") as zip_file:\n            # Filter file names based on extensions in TEXT_FILE_TYPES and ignore hidden files\n            valid_files = [\n                name\n                for name in zip_file.namelist()\n                if (\n                    any(name.endswith(ext) for ext in TEXT_FILE_TYPES)\n                    and not name.startswith(\"__MACOSX\")\n                    and not name.startswith(\".\")\n                )\n            ]\n\n            # Raise an error if no valid files found\n            if not valid_files:\n                self.log(\"No valid files in the zip archive.\")\n\n                # Return empty data if silent_errors is True\n                if silent_errors:\n                    return data  # type: ignore[return-value]\n\n                # Raise an error if no valid files found\n                msg = \"No valid files in the zip archive.\"\n                raise ValueError(msg)\n\n            # Define a function to process each file\n            def process_file(file_name, silent_errors=silent_errors):\n                with NamedTemporaryFile(delete=False) as temp_file:\n                    temp_path = Path(temp_file.name).with_name(file_name)\n                    with zip_file.open(file_name) as file_content:\n                        temp_path.write_bytes(file_content.read())\n                try:\n                    return self._process_single_file(temp_path, silent_errors=silent_errors)\n                finally:\n                    temp_path.unlink()\n\n            # Process files in parallel if specified\n            if parallel:\n                self.log(\n                    f\"Initializing parallel Thread Pool Executor with max workers: \"\n                    f\"{self.concurrency_multithreading}.\"\n                )\n\n                # Process files in parallel\n                initial_data = parallel_load_data(\n                    valid_files,\n                    silent_errors=silent_errors,\n                    load_function=process_file,\n                    max_concurrency=self.concurrency_multithreading,\n                )\n\n                # Filter out empty data\n                data = list(filter(None, initial_data))\n            else:\n                # Sequential processing\n                data = [process_file(file_name) for file_name in valid_files]\n\n        self.log(f\"Successfully processed zip file: {zip_path.name}.\")\n\n        return data  # type: ignore[return-value]\n\n    def _process_single_file(self, file_path: Path, *, silent_errors: bool = False) -> Data:\n        \"\"\"Process a single file.\n\n        Args:\n            file_path: Path to the file.\n            silent_errors: Suppresses errors if True.\n\n        Returns:\n            Data: Parsed data from the file.\n\n        Raises:\n            ValueError: For unsupported file formats.\n        \"\"\"\n        # Check if the file type is supported\n        if not any(file_path.suffix == ext for ext in [\".\" + f for f in TEXT_FILE_TYPES]):\n            self.log(f\"Unsupported file type: {file_path.suffix}\")\n\n            # Return empty data if silent_errors is True\n            if silent_errors:\n                return Data()\n\n            msg = f\"Unsupported file type: {file_path.suffix}\"\n            raise ValueError(msg)\n\n        try:\n            # Parse the text file as appropriate\n            data = parse_text_file_to_data(str(file_path), silent_errors=silent_errors)  # type: ignore[assignment]\n            if not data:\n                data = Data()\n\n            self.log(f\"Successfully processed file: {file_path.name}.\")\n        except Exception as e:\n            self.log(f\"Error processing file {file_path.name}: {e}\")\n\n            # Return empty data if silent_errors is True\n            if not silent_errors:\n                raise\n\n            data = Data()\n\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "concurrency_multithreading": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concurrency_multithreading",
                "value": 4,
                "display_name": "Multithreading Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of workers to use, if concurrency is enabled",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_multithreading": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": false,
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "If true, parallel processing will be enabled for zip files.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Load a file to be used in your project.",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "File",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "silent_errors",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "File-JLkjD",
          "description": "A generic file loader.",
          "display_name": "File"
        },
        "selected": false,
        "width": 320,
        "height": 231,
        "positionAbsolute": {
          "x": -1690.986305115724,
          "y": 346.02648971374686
        },
        "dragging": false
      },
      {
        "id": "SplitText-EIkgR",
        "type": "genericNode",
        "position": {
          "x": -1245.9862644049654,
          "y": 212.6958857209412
        },
        "data": {
          "type": "SplitText",
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "SplitText-EIkgR",
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text"
        },
        "selected": false,
        "width": 320,
        "height": 474,
        "positionAbsolute": {
          "x": -1245.9862644049654,
          "y": 212.6958857209412
        },
        "dragging": false
      },
      {
        "id": "Prompt-H1qCU",
        "type": "genericNode",
        "position": {
          "x": 199.72748023132476,
          "y": 76.51441060773848
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "# LLM Prompt: Generate Detailed Podcast Script\n\nUsing the provided data: {data}, create a comprehensive podcast script featuring {number_of_speakers} speakers, Person A, Person B, ..., with a duration of the maximium of the time keeping a concise conversation. The output should be in CSV format with the following columns: Speaker, Dialogue and Duration (in seconds).\n\n## Output Format:\n\n{output_format}\n\n## Additional Notes:\n\n{additional_details}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "data",
                "display_name": "data",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "number_of_speakers": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "number_of_speakers",
                "display_name": "number_of_speakers",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "output_format": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "output_format",
                "display_name": "output_format",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "additional_details": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "additional_details",
                "display_name": "additional_details",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "data",
                "number_of_speakers",
                "output_format",
                "additional_details"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "Prompt-H1qCU"
        },
        "selected": false,
        "width": 320,
        "height": 604,
        "positionAbsolute": {
          "x": 199.72748023132476,
          "y": 76.51441060773848
        },
        "dragging": false
      },
      {
        "id": "ParseData-wLaBA",
        "type": "genericNode",
        "position": {
          "x": -331.14349544545655,
          "y": 239.3456115466342
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "ParseData-wLaBA",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": -331.14349544545655,
          "y": 239.3456115466342
        },
        "dragging": false
      },
      {
        "id": "MarkdownDataExtractorComponent-T063l",
        "type": "genericNode",
        "position": {
          "x": 1015.8420749504644,
          "y": 250.58774730106416
        },
        "data": {
          "type": "MarkdownDataExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "block_type": {
                "trace_as_metadata": true,
                "options": [
                  "csv",
                  "json",
                  "yaml"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "block_type",
                "value": "csv",
                "display_name": "Block Type (csv, json, yaml)",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nimport csv\nfrom io import StringIO\nimport re\nimport json\nfrom typing import List, Dict, Any, Union\n\nclass MarkdownDataExtractorComponent(Component):\n    display_name = \"Extract Block from Markdown\"\n    description = \"Extracts data from markdown code blocks and converts it to a structured format.\"\n    documentation: str = \"https://docs.langflow.org/components/custom\"\n    icon = \"FileText\"\n    name = \"MarkdownDataExtractorComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Markdown Text\", value=\"\"),\n        DropdownInput(name=\"block_type\", display_name=\"Block Type (csv, json, yaml)\", options=[\"csv\", \"json\", \"yaml\"], value=\"csv\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Data\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def _extract_code_block(self, markdown_text: str, block_type: str) -> str:\n        \"\"\"Extract content from a specific type of code block in markdown text.\"\"\"\n        pattern = rf'```{block_type}\\n(.*?)\\n```'\n        match = re.search(pattern, markdown_text, re.DOTALL)\n        if not match:\n            raise ValueError(f\"No {block_type} content found between triple backticks.\")\n        return match.group(1)\n\n    def _parse_csv(self, csv_string: str) -> List[Dict[str, Any]]:\n        \"\"\"Parse CSV string into a list of dictionaries.\"\"\"\n        csv_file = StringIO(csv_string)\n        csv_reader = csv.DictReader(csv_file)\n        return [row for row in csv_reader]\n\n    def _parse_json(self, json_string: str) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Parse JSON string into a dictionary or list of dictionaries.\"\"\"\n        return json.loads(json_string)\n\n    def _parse_yaml(self, yaml_string: str) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Parse YAML string into a dictionary or list of dictionaries.\"\"\"\n        import yaml\n        return yaml.safe_load(yaml_string)\n\n    def build_output(self) -> Union[List[Data], Data]:\n        try:\n            block_type = self.block_type.lower()\n            \n            if block_type not in ['csv', 'json', 'yaml']:\n                raise ValueError(\"Invalid block_type. Must be 'csv', 'json', or 'yaml'.\")\n            \n            extracted_content = self._extract_code_block(self.input_value, block_type)\n            \n            if block_type == 'csv':\n                data = self._parse_csv(extracted_content)\n            elif block_type == 'json':\n                data = self._parse_json(extracted_content)\n            elif block_type == 'yaml':\n                data = self._parse_yaml(extracted_content)\n            \n            if isinstance(data, list):\n                data_objects = [Data(**entry) for entry in data]\n                self.status = data_objects\n                return data_objects\n            elif isinstance(data, dict):\n                self.status = Data(**data)\n                return self.status\n            else:\n                raise ValueError(f\"Unexpected data format from {block_type} parsing.\")\n\n        except ValueError as ve:\n            self.status = f\"Error: {str(ve)}\"\n            return Data(error=str(ve))\n        except json.JSONDecodeError as je:\n            self.status = f\"JSON Decode Error: {str(je)}\"\n            return Data(error=f\"JSON Decode Error: {str(je)}\")\n        except yaml.YAMLError as ye:\n            self.status = f\"YAML Parse Error: {str(ye)}\"\n            return Data(error=f\"YAML Parse Error: {str(ye)}\")\n        except Exception as e:\n            self.status = f\"Unexpected Error: {str(e)}\"\n            return Data(error=f\"Unexpected Error: {str(e)}\")",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Markdown Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Extracts data from markdown code blocks and converts it to a structured format.",
            "icon": "FileText",
            "base_classes": [
              "Data"
            ],
            "display_name": "Extract Block From Markdown",
            "documentation": "https://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Extracted Data",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "block_type"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "MarkdownDataExtractorComponent-T063l"
        },
        "selected": false,
        "width": 320,
        "height": 339,
        "positionAbsolute": {
          "x": 1015.8420749504644,
          "y": 250.58774730106416
        },
        "dragging": false
      },
      {
        "id": "MultiSpeakerAudioGenerator-WmDnl",
        "type": "genericNode",
        "position": {
          "x": 1485.7373773832887,
          "y": 133.0229590582241
        },
        "data": {
          "type": "MultiSpeakerAudioGenerator",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Data Input Dialogue",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The Input Data here should have the keys Speaker, Dialogue and Duration (in seconds). Here is an example: \nSpeaker, Dialogue, Duration\nPerson A, Some Dialogue Here , 20\nPerson B, Some Other Here , 10",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom langflow.custom import Component\nfrom langflow.io import Output, DataInput, SecretStrInput\nfrom openai import OpenAI\nimport os\nfrom langflow.schema import Data\nfrom pydub import AudioSegment\nimport tempfile\nimport warnings\n\nclass MultiSpeakerAudioGenerator(Component):\n    display_name = \"OpenAI Whisper Data to Speech\"\n    description = \"Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.\"\n    documentation: str = \"https://platform.openai.com/docs/guides/text-to-speech\"\n    icon = \"OpenAI\"\n    name = \"MultiSpeakerAudioGenerator\"\n    inputs = [\n        DataInput(name=\"input_value\", display_name=\"Data Input Dialogue\", info=\"The Input Data here should have the keys Speaker, Dialogue and Duration (in seconds). Here is an example: \\nSpeaker, Dialogue, Duration\\nPerson A, Some Dialogue Here , 20\\nPerson B, Some Other Here , 10\"),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        MessageTextInput(\n            name=\"filepath\",\n            display_name=\"File Path to Save\",\n            info=\"File Path to save audio result (Do NOT include file extension), it will always be saved as mp3.\",\n            advanced=False,\n            value=\"audio_result\"\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Generated Audio Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        \"\"\"\n        Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.\n        \"\"\"\n        # Validate the API key\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key must be provided.\")\n        \n        client = OpenAI(api_key=self.api_key)\n        \n        if not client.api_key:\n            raise ValueError(\"Invalid OpenAI API key set in environment variable 'OPENAI_API_KEY'.\")\n\n        # Initialize empty audio segment\n        combined_audio = AudioSegment.silent(duration=0)\n        output_info = []\n        available_voices = ['alloy', 'nova', 'echo', 'fable', 'onyx', 'shimmer']\n        speaker_voice_map = {}\n        voice_index = 0\n\n        # Create a temporary directory to store intermediate audio files\n        with tempfile.TemporaryDirectory() as temp_dir:\n            for idx, data_item in enumerate(self.input_value):\n                # Extract speaker and dialogue information\n                try:\n                    speaker = data_item.data['Speaker']\n                    dialogue = data_item.data['Dialogue']\n                except KeyError as e:\n                    raise ValueError(f\"Missing required data field: {str(e)}\")\n                \n                # Assign a voice to each speaker sequentially\n                if speaker not in speaker_voice_map:\n                    speaker_voice_map[speaker] = available_voices[voice_index % len(available_voices)]\n                    voice_index += 1\n                \n                voice = speaker_voice_map[speaker]\n\n                # Generate speech audio\n                try:\n                    response = client.audio.speech.create(\n                        model=\"tts-1\",\n                        voice=voice,\n                        input=dialogue\n                    )\n                except Exception as e:\n                    raise RuntimeError(f\"An error occurred while generating speech for {speaker}: {e}\")\n                \n                # Save the generated audio to a temporary file\n                temp_audio_file = os.path.join(temp_dir, f\"temp_{idx}.mp3\")\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\", DeprecationWarning)\n                    response.stream_to_file(temp_audio_file)\n\n                # Append the generated audio to the combined audio segment\n                try:\n                    audio_segment = AudioSegment.from_mp3(temp_audio_file)\n                    combined_audio += audio_segment\n                except Exception as e:\n                    raise RuntimeError(f\"An error occurred while processing the audio file for {speaker}: {e}\")\n                \n                # Add speaker dialogue info to output\n                output_info.append({\n                    'speaker': speaker,\n                    'dialogue': dialogue,\n                    'voice': voice\n                })\n\n        # Export the final combined audio file\n        final_audio_file = f\"{self.filepath}.mp3\"\n        try:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", ResourceWarning)\n                combined_audio.export(final_audio_file, format=\"mp3\")\n        except Exception as e:\n            raise RuntimeError(f\"Failed to export combined audio file: {e}\")\n\n        # Return the data output\n        return Data(\n            name=\"output\",\n            data={\n                'audio_file': final_audio_file,\n                'dialogue_info': output_info\n            },\n            text_key=\"audio_file\"\n        )",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "filepath": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "filepath",
                "value": "audio_result4",
                "display_name": "File Path to Save",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "File Path to save audio result (Do NOT include file extension), it will always be saved as mp3.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.",
            "icon": "OpenAI",
            "base_classes": [
              "Data"
            ],
            "display_name": "OpenAI Whisper Data to Speech",
            "documentation": "https://platform.openai.com/docs/guides/text-to-speech",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Generated Audio Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "api_key",
              "filepath"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "MultiSpeakerAudioGenerator-WmDnl"
        },
        "selected": false,
        "width": 320,
        "height": 410,
        "dragging": false,
        "positionAbsolute": {
          "x": 1485.7373773832887,
          "y": 133.0229590582241
        }
      },
      {
        "id": "TextInput-kZqKx",
        "type": "genericNode",
        "position": {
          "x": -132.35001564260676,
          "y": 589.7234795081366
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "4",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Number of Speakers",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "TextInput-kZqKx",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "dragging": false,
        "positionAbsolute": {
          "x": -132.35001564260676,
          "y": 589.7234795081366
        }
      },
      {
        "id": "OpenAIModel-SBKMK",
        "type": "genericNode",
        "position": {
          "x": 620.6615842503197,
          "y": 98.52487468964858
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "OpenAIModel-SBKMK",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI"
        },
        "selected": false,
        "width": 320,
        "height": 672,
        "positionAbsolute": {
          "x": 620.6615842503197,
          "y": 98.52487468964858
        },
        "dragging": false
      },
      {
        "id": "note-QODCb",
        "type": "noteNode",
        "position": {
          "x": -1533.1415565287136,
          "y": -624.2436683231297
        },
        "data": {
          "node": {
            "description": "This Flow Application needs two additional packages (pydub and ffmpeg). If you do not have them installed yet, please install them using the componentes in the right side.\nFor pydub use pip installation and for ffmpeg you need to choice accordingly to your operational system, prefer using brew for macos and apt for linux debian based systems.",
            "display_name": "Installing Additional Packages",
            "documentation": "",
            "template": {
              "backgroundColor": "amber"
            }
          },
          "type": "note",
          "id": "note-QODCb"
        },
        "selected": false,
        "width": 324,
        "height": 650,
        "positionAbsolute": {
          "x": -1533.1415565287136,
          "y": -624.2436683231297
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 324,
          "height": 650
        }
      },
      {
        "id": "PackageInstallerComponent-qH7zC",
        "type": "genericNode",
        "position": {
          "x": -1206.4089858770624,
          "y": -624.8536887236112
        },
        "data": {
          "type": "PackageInstallerComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import subprocess\nfrom langflow.custom import Component\nfrom langflow.inputs import DropdownInput, MessageTextInput, SecretStrInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\n\nclass PackageInstallerComponent(Component):\n    display_name = \"Package Installer\"\n    description = \"Installs a specified package using pip, brew, or apt. Supports password input for sudo commands for apt.\"\n    icon = \"package\"\n\n    # Define inputs: method of installation, package name, and password\n    inputs = [\n        DropdownInput(\n            name=\"install_method\",\n            display_name=\"Installation Method\",\n            options=[\"pip\", \"brew\", \"apt\"],\n            info=\"Choose how to install the package.\",\n        ),\n        MessageTextInput(\n            name=\"package_name\",\n            display_name=\"Package Name\",\n            info=\"Specify the name of the package to install.\",\n        ),\n        SecretStrInput(\n            name=\"sudo_password\",\n            display_name=\"Sudo Password\",\n            info=\"Enter your password for sudo (required for apt installations).\",\n        ),\n        MessageTextInput(\n            name=\"pass_value\",\n            display_name=\"Text to Pass\",\n            info=\"Pass a text to the next component in the Pass Output.\"\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Install Output\", name=\"install_output\", method=\"install_packages\"),\n        Output(display_name=\"Pass\", name=\"pass\", method=\"build_pass\"),\n    ]\n\n    def install_packages(self) -> Message:\n        install_method = self.install_method\n        package_name = self.package_name\n        sudo_password = self.sudo_password\n        result = \"\"\n\n        if not package_name:\n            raise Exception(\"Error: No package name provided.\")\n\n        try:\n            if install_method == \"pip\":\n                # No password needed for pip installations\n                result = self.run_command([\"pip\", \"install\", package_name])\n\n            elif install_method == \"brew\":\n                # Homebrew should not be run with sudo\n                result = self.run_command([\"brew\", \"install\", package_name])\n\n            elif install_method == \"apt\":\n                # Use sudo password for apt installation\n                result = self.run_command_with_sudo([\"apt\", \"update\"], sudo_password)\n                result += \"\\n\" + self.run_command_with_sudo([\"apt\", \"install\", \"-y\", package_name], sudo_password)\n\n        except Exception as e:\n            self.status = f\"Installation failed: {str(e)}\"\n            raise  # Re-raise the exception for Langflow to capture and handle\n\n        # Store result as status and return it in Data object\n        self.status = result\n        return Message(content=result)  # Updated line\n\n    def run_command(self, command: list) -> str:\n        \"\"\"Run a command without sudo.\"\"\"\n        try:\n            result = subprocess.run(command, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            raise Exception(f\"Command failed: {e.stderr}\")\n\n    def run_command_with_sudo(self, command: list, password: str) -> str:\n        \"\"\"Run a command with sudo, using the provided password for apt installations.\"\"\"\n        try:\n            # Prepend echo and pipe the password to the sudo command for apt\n            sudo_command = ['sudo', '-S'] + command\n            process = subprocess.run(sudo_command, input=password + \"\\n\", text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            if process.returncode != 0:\n                raise Exception(f\"Command failed: {process.stderr}\")\n            return process.stdout\n        except subprocess.CalledProcessError as e:\n            raise Exception(f\"Command failed: {e.stderr}\")\n    \n    def build_pass(self) -> Message:\n        return Message(content=self.pass_value)  # Updated line\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "install_method": {
                "trace_as_metadata": true,
                "options": [
                  "pip",
                  "brew",
                  "apt"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "install_method",
                "value": "pip",
                "display_name": "Installation Method",
                "advanced": false,
                "dynamic": false,
                "info": "Choose how to install the package.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "package_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "package_name",
                "value": "pydub",
                "display_name": "Package Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Specify the name of the package to install.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "pass_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "pass_value",
                "value": "",
                "display_name": "Text to Pass",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Pass a text to the next component in the Pass Output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sudo_password": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sudo_password",
                "value": "",
                "display_name": "Sudo Password",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter your password for sudo (required for apt installations).",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Installs a specified package using pip, brew, or apt. Supports password input for sudo commands for apt.",
            "icon": "package",
            "base_classes": [
              "Message"
            ],
            "display_name": "Install Dependencies",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "install_output",
                "display_name": "Install Output",
                "method": "install_packages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "pass",
                "display_name": "Pass",
                "method": "build_pass",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "install_method",
              "package_name",
              "sudo_password",
              "pass_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "PackageInstallerComponent-qH7zC"
        },
        "selected": false,
        "width": 320,
        "height": 580,
        "positionAbsolute": {
          "x": -1206.4089858770624,
          "y": -624.8536887236112
        },
        "dragging": false
      },
      {
        "id": "PackageInstallerComponent-oywxA",
        "type": "genericNode",
        "position": {
          "x": -766.8336393384793,
          "y": -607.8465583203456
        },
        "data": {
          "type": "PackageInstallerComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import subprocess\nfrom langflow.custom import Component\nfrom langflow.inputs import DropdownInput, MessageTextInput, SecretStrInput\nfrom langflow.template import Output\nfrom langflow.schema.message import Message\n\nclass PackageInstallerComponent(Component):\n    display_name = \"Package Installer\"\n    description = \"Installs a specified package using pip, brew, or apt. Supports password input for sudo commands for apt.\"\n    icon = \"package\"\n\n    # Define inputs: method of installation, package name, and password\n    inputs = [\n        DropdownInput(\n            name=\"install_method\",\n            display_name=\"Installation Method\",\n            options=[\"pip\", \"brew\", \"apt\"],\n            info=\"Choose how to install the package.\",\n        ),\n        MessageTextInput(\n            name=\"package_name\",\n            display_name=\"Package Name\",\n            info=\"Specify the name of the package to install.\",\n        ),\n        SecretStrInput(\n            name=\"sudo_password\",\n            display_name=\"Sudo Password\",\n            info=\"Enter your password for sudo (required for apt installations).\",\n        ),\n        MessageTextInput(\n            name=\"pass_value\",\n            display_name=\"Text to Pass\",\n            info=\"Pass a text to the next component in the Pass Output.\"\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Install Output\", name=\"install_output\", method=\"install_packages\"),\n        Output(display_name=\"Pass\", name=\"pass\", method=\"build_pass\"),\n    ]\n\n    def install_packages(self) -> Message:\n        install_method = self.install_method\n        package_name = self.package_name\n        sudo_password = self.sudo_password\n        result = \"\"\n\n        if not package_name:\n            raise Exception(\"Error: No package name provided.\")\n\n        try:\n            if install_method == \"pip\":\n                # No password needed for pip installations\n                result = self.run_command([\"pip\", \"install\", package_name])\n\n            elif install_method == \"brew\":\n                # Homebrew should not be run with sudo\n                result = self.run_command([\"brew\", \"install\", package_name])\n\n            elif install_method == \"apt\":\n                # Use sudo password for apt installation\n                result = self.run_command_with_sudo([\"apt\", \"update\"], sudo_password)\n                result += \"\\n\" + self.run_command_with_sudo([\"apt\", \"install\", \"-y\", package_name], sudo_password)\n\n        except Exception as e:\n            self.status = f\"Installation failed: {str(e)}\"\n            raise  # Re-raise the exception for Langflow to capture and handle\n\n        # Store result as status and return it in Data object\n        self.status = result\n        return Message(content=result)  # Updated line\n\n    def run_command(self, command: list) -> str:\n        \"\"\"Run a command without sudo.\"\"\"\n        try:\n            result = subprocess.run(command, check=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            raise Exception(f\"Command failed: {e.stderr}\")\n\n    def run_command_with_sudo(self, command: list, password: str) -> str:\n        \"\"\"Run a command with sudo, using the provided password for apt installations.\"\"\"\n        try:\n            # Prepend echo and pipe the password to the sudo command for apt\n            sudo_command = ['sudo', '-S'] + command\n            process = subprocess.run(sudo_command, input=password + \"\\n\", text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            if process.returncode != 0:\n                raise Exception(f\"Command failed: {process.stderr}\")\n            return process.stdout\n        except subprocess.CalledProcessError as e:\n            raise Exception(f\"Command failed: {e.stderr}\")\n    \n    def build_pass(self) -> Message:\n        return Message(content=self.pass_value)  # Updated line\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "install_method": {
                "trace_as_metadata": true,
                "options": [
                  "pip",
                  "brew",
                  "apt"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "install_method",
                "value": "brew",
                "display_name": "Installation Method",
                "advanced": false,
                "dynamic": false,
                "info": "Choose how to install the package.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "package_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "package_name",
                "value": "ffmpeg",
                "display_name": "Package Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Specify the name of the package to install.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "pass_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "pass_value",
                "value": "",
                "display_name": "Text to Pass",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Pass a text to the next component in the Pass Output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sudo_password": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sudo_password",
                "value": "",
                "display_name": "Sudo Password",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter your password for sudo (required for apt installations).",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Installs a specified package using pip, brew, or apt. Supports password input for sudo commands for apt.",
            "icon": "package",
            "base_classes": [
              "Message"
            ],
            "display_name": "Install Dependencies",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "install_output",
                "display_name": "Install Output",
                "method": "install_packages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "pass",
                "display_name": "Pass",
                "method": "build_pass",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "install_method",
              "package_name",
              "sudo_password",
              "pass_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "PackageInstallerComponent-oywxA"
        },
        "selected": false,
        "width": 320,
        "height": 580,
        "positionAbsolute": {
          "x": -766.8336393384793,
          "y": -607.8465583203456
        },
        "dragging": false
      },
      {
        "id": "TextInput-e5TZN",
        "type": "genericNode",
        "position": {
          "x": -100.4704786070489,
          "y": 21.119091392519607
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "- Be specific in describing tones (e.g., sarcastic, curious, professional) and emotions (e.g., surprised, amused, concerned).\n- Include non-verbal cues in the dialogue when relevant (e.g., \"[laughs]\", \"[sighs]\").\n- For sound effects, be precise (e.g., \"Phone ringing\", \"Door creaking\", \"Applause\").\n- Ensure the content is coherent, factual, and aligns with the provided data.\n- If the data includes technical terms or complex concepts, incorporate brief explanations or analogies to make the content accessible to a general audience.\n\nPlease generate a detailed, engaging, and realistic podcast script based on these guidelines.",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Additional Details",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "TextInput-e5TZN",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "dragging": false,
        "positionAbsolute": {
          "x": -100.4704786070489,
          "y": 21.119091392519607
        }
      },
      {
        "id": "TextInput-tsS3y",
        "type": "genericNode",
        "position": {
          "x": 15.14291980800715,
          "y": 749.7215692193756
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "```csv\nSpeaker,Dialogue,Duration\nPerson A,\"Hello and welcome to our podcast!\"\nPerson B,\"Thanks for having me. I'm excited to discuss [topic] today.\"\n...",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Output Format",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "id": "TextInput-tsS3y",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 15.14291980800715,
          "y": 749.7215692193756
        },
        "dragging": false
      },
      {
        "id": "note-8Gc99",
        "type": "noteNode",
        "position": {
          "x": 255.14998156838212,
          "y": 222.7009153358001
        },
        "data": {
          "node": {
            "description": "",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-8Gc99"
        },
        "selected": false,
        "width": 325,
        "height": 325
      },
      {
        "id": "note-MIAXt",
        "type": "noteNode",
        "position": {
          "x": 199.38907957923163,
          "y": -260.0666357113615
        },
        "data": {
          "node": {
            "description": "If you want to change the behavior of the podcast script, you can change the Prompt Template manually at this part.\n\nThe Text Inputs below can be customized in the Playground, they provide basic adjust if you need to, like additional details, number of speakers and output format.",
            "display_name": "Making Additional Changes",
            "documentation": "",
            "template": {
              "backgroundColor": "indigo"
            }
          },
          "type": "note",
          "id": "note-MIAXt"
        },
        "selected": false,
        "width": 382,
        "height": 324,
        "positionAbsolute": {
          "x": 199.38907957923163,
          "y": -260.0666357113615
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 382,
          "height": 324
        }
      },
      {
        "id": "MarkdownDataExtractorComponent-I4ZkA",
        "type": "genericNode",
        "position": {
          "x": 1075.1331632035062,
          "y": 779.0848899696621
        },
        "data": {
          "type": "MarkdownDataExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "block_type": {
                "trace_as_metadata": true,
                "options": [
                  "csv",
                  "json",
                  "yaml"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "block_type",
                "value": "csv",
                "display_name": "Block Type (csv, json, yaml)",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nimport csv\nfrom io import StringIO\nimport re\nimport json\nfrom typing import List, Dict, Any, Union\n\nclass MarkdownDataExtractorComponent(Component):\n    display_name = \"Extract Block from Markdown\"\n    description = \"Extracts data from markdown code blocks and converts it to a structured format.\"\n    documentation: str = \"https://docs.langflow.org/components/custom\"\n    icon = \"FileText\"\n    name = \"MarkdownDataExtractorComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Markdown Text\", value=\"\"),\n        DropdownInput(name=\"block_type\", display_name=\"Block Type (csv, json, yaml)\", options=[\"csv\", \"json\", \"yaml\"], value=\"csv\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Data\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def _extract_code_block(self, markdown_text: str, block_type: str) -> str:\n        \"\"\"Extract content from a specific type of code block in markdown text.\"\"\"\n        pattern = rf'```{block_type}\\n(.*?)\\n```'\n        match = re.search(pattern, markdown_text, re.DOTALL)\n        if not match:\n            raise ValueError(f\"No {block_type} content found between triple backticks.\")\n        return match.group(1)\n\n    def _parse_csv(self, csv_string: str) -> List[Dict[str, Any]]:\n        \"\"\"Parse CSV string into a list of dictionaries.\"\"\"\n        csv_file = StringIO(csv_string)\n        csv_reader = csv.DictReader(csv_file)\n        return [row for row in csv_reader]\n\n    def _parse_json(self, json_string: str) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Parse JSON string into a dictionary or list of dictionaries.\"\"\"\n        return json.loads(json_string)\n\n    def _parse_yaml(self, yaml_string: str) -> Union[Dict[str, Any], List[Dict[str, Any]]]:\n        \"\"\"Parse YAML string into a dictionary or list of dictionaries.\"\"\"\n        import yaml\n        return yaml.safe_load(yaml_string)\n\n    def build_output(self) -> Union[List[Data], Data]:\n        try:\n            block_type = self.block_type.lower()\n            \n            if block_type not in ['csv', 'json', 'yaml']:\n                raise ValueError(\"Invalid block_type. Must be 'csv', 'json', or 'yaml'.\")\n            \n            extracted_content = self._extract_code_block(self.input_value, block_type)\n            \n            if block_type == 'csv':\n                data = self._parse_csv(extracted_content)\n            elif block_type == 'json':\n                data = self._parse_json(extracted_content)\n            elif block_type == 'yaml':\n                data = self._parse_yaml(extracted_content)\n            \n            if isinstance(data, list):\n                data_objects = [Data(**entry) for entry in data]\n                self.status = data_objects\n                return data_objects\n            elif isinstance(data, dict):\n                self.status = Data(**data)\n                return self.status\n            else:\n                raise ValueError(f\"Unexpected data format from {block_type} parsing.\")\n\n        except ValueError as ve:\n            self.status = f\"Error: {str(ve)}\"\n            return Data(error=str(ve))\n        except json.JSONDecodeError as je:\n            self.status = f\"JSON Decode Error: {str(je)}\"\n            return Data(error=f\"JSON Decode Error: {str(je)}\")\n        except yaml.YAMLError as ye:\n            self.status = f\"YAML Parse Error: {str(ye)}\"\n            return Data(error=f\"YAML Parse Error: {str(ye)}\")\n        except Exception as e:\n            self.status = f\"Unexpected Error: {str(e)}\"\n            return Data(error=f\"Unexpected Error: {str(e)}\")",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Markdown Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Extracts data from markdown code blocks and converts it to a structured format.",
            "icon": "FileText",
            "base_classes": [
              "Data"
            ],
            "display_name": "Extract Block From Markdown",
            "documentation": "https://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Extracted Data",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "block_type"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "MarkdownDataExtractorComponent-I4ZkA"
        },
        "selected": false,
        "width": 320,
        "height": 339,
        "positionAbsolute": {
          "x": 1075.1331632035062,
          "y": 779.0848899696621
        },
        "dragging": false
      },
      {
        "id": "MultiSpeakerAudioGenerator-p2vl0",
        "type": "genericNode",
        "position": {
          "x": 1556.3257087233676,
          "y": 718.2878050424381
        },
        "data": {
          "type": "MultiSpeakerAudioGenerator",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Data Input Dialogue",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The Input Data here should have the keys Speaker, Dialogue and Duration (in seconds). Here is an example: \nSpeaker, Dialogue, Duration\nPerson A, Some Dialogue Here , 20\nPerson B, Some Other Here , 10",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom langflow.custom import Component\nfrom langflow.io import Output, DataInput, SecretStrInput\nfrom openai import OpenAI\nimport os\nfrom langflow.schema import Data\nfrom pydub import AudioSegment\nimport tempfile\nimport warnings\n\nclass MultiSpeakerAudioGenerator(Component):\n    display_name = \"OpenAI Whisper Data to Speech\"\n    description = \"Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.\"\n    documentation: str = \"https://platform.openai.com/docs/guides/text-to-speech\"\n    icon = \"OpenAI\"\n    name = \"MultiSpeakerAudioGenerator\"\n    inputs = [\n        DataInput(name=\"input_value\", display_name=\"Data Input Dialogue\", info=\"The Input Data here should have the keys Speaker, Dialogue and Duration (in seconds). Here is an example: \\nSpeaker, Dialogue, Duration\\nPerson A, Some Dialogue Here , 20\\nPerson B, Some Other Here , 10\"),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        MessageTextInput(\n            name=\"filepath\",\n            display_name=\"File Path to Save\",\n            info=\"File Path to save audio result (Do NOT include file extension), it will always be saved as mp3.\",\n            advanced=False,\n            value=\"audio_result\"\n        )\n    ]\n    outputs = [\n        Output(display_name=\"Generated Audio Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        \"\"\"\n        Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.\n        \"\"\"\n        # Validate the API key\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key must be provided.\")\n        \n        client = OpenAI(api_key=self.api_key)\n        \n        if not client.api_key:\n            raise ValueError(\"Invalid OpenAI API key set in environment variable 'OPENAI_API_KEY'.\")\n\n        # Initialize empty audio segment\n        combined_audio = AudioSegment.silent(duration=0)\n        output_info = []\n        available_voices = ['alloy', 'nova', 'echo', 'fable', 'onyx', 'shimmer']\n        speaker_voice_map = {}\n        voice_index = 0\n\n        # Create a temporary directory to store intermediate audio files\n        with tempfile.TemporaryDirectory() as temp_dir:\n            for idx, data_item in enumerate(self.input_value):\n                # Extract speaker and dialogue information\n                try:\n                    speaker = data_item.data['Speaker']\n                    dialogue = data_item.data['Dialogue']\n                except KeyError as e:\n                    raise ValueError(f\"Missing required data field: {str(e)}\")\n                \n                # Assign a voice to each speaker sequentially\n                if speaker not in speaker_voice_map:\n                    speaker_voice_map[speaker] = available_voices[voice_index % len(available_voices)]\n                    voice_index += 1\n                \n                voice = speaker_voice_map[speaker]\n\n                # Generate speech audio\n                try:\n                    response = client.audio.speech.create(\n                        model=\"tts-1\",\n                        voice=voice,\n                        input=dialogue\n                    )\n                except Exception as e:\n                    raise RuntimeError(f\"An error occurred while generating speech for {speaker}: {e}\")\n                \n                # Save the generated audio to a temporary file\n                temp_audio_file = os.path.join(temp_dir, f\"temp_{idx}.mp3\")\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\", DeprecationWarning)\n                    response.stream_to_file(temp_audio_file)\n\n                # Append the generated audio to the combined audio segment\n                try:\n                    audio_segment = AudioSegment.from_mp3(temp_audio_file)\n                    combined_audio += audio_segment\n                except Exception as e:\n                    raise RuntimeError(f\"An error occurred while processing the audio file for {speaker}: {e}\")\n                \n                # Add speaker dialogue info to output\n                output_info.append({\n                    'speaker': speaker,\n                    'dialogue': dialogue,\n                    'voice': voice\n                })\n\n        # Export the final combined audio file\n        final_audio_file = f\"{self.filepath}.mp3\"\n        try:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", ResourceWarning)\n                combined_audio.export(final_audio_file, format=\"mp3\")\n        except Exception as e:\n            raise RuntimeError(f\"Failed to export combined audio file: {e}\")\n\n        # Return the data output\n        return Data(\n            name=\"output\",\n            data={\n                'audio_file': final_audio_file,\n                'dialogue_info': output_info\n            },\n            text_key=\"audio_file\"\n        )",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "filepath": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "filepath",
                "value": "audio_result4",
                "display_name": "File Path to Save",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "File Path to save audio result (Do NOT include file extension), it will always be saved as mp3.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generates a single speech audio file from dialogue data with multiple speakers using OpenAI's TTS API.",
            "icon": "OpenAI",
            "base_classes": [
              "Data"
            ],
            "display_name": "OpenAI Whisper Data to Speech",
            "documentation": "https://platform.openai.com/docs/guides/text-to-speech",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Generated Audio Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "api_key",
              "filepath"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "MultiSpeakerAudioGenerator-p2vl0"
        },
        "selected": false,
        "width": 320,
        "height": 410,
        "positionAbsolute": {
          "x": 1556.3257087233676,
          "y": 718.2878050424381
        },
        "dragging": false
      },
      {
        "id": "TextInput-qzzR3",
        "type": "genericNode",
        "position": {
          "x": 625.5287779422649,
          "y": 863.7125320097903
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "```csv\nSpeaker,Dialogue,Duration\nPerson A,\"Hello and welcome to our podcast, where we dive into the mysteries of the universe and beyond. I'm your host, and today we're tackling a topic that's puzzled scientists for decades: the information loss paradox in black holes.\",10\nPerson B,\"Thanks for having me. I'm thrilled to be here to discuss this fascinating subject. It's a topic that combines the enigmatic nature of black holes with the fundamental principles of quantum mechanics.\",8\nPerson A,\"Absolutely! Let's start with a bit of background. The black hole information paradox was first introduced in 1967 by Werner Israel, who showed that the Schwarzschild metric was the only static vacuum black hole solution. This led to the no-hair theorem, which suggests that black holes can be completely described by just three properties: mass, angular momentum, and electric charge.\",15\nPerson B,\"Right, and the paradox arises because, according to classical theory, all other information about the matter that formed a black hole is lost to the outside universe. But things got more complicated when Stephen Hawking discovered that black holes can emit radiation, now known as Hawking radiation.\",12\nPerson A,\"Exactly. Hawking's discovery suggested that black holes could eventually evaporate completely, raising the question: what happens to the information that fell into the black hole? If it's lost, it would mean that quantum mechanics, which is supposed to be unitary and information-preserving, might not hold in these extreme conditions.\",14\nPerson B,\"That's the crux of the paradox. If information is truly lost, it would imply that pure quantum states could decay into mixed states, challenging the very foundation of quantum mechanics. However, many physicists believe that there must be a mechanism that preserves information, even if it's not yet fully understood.\",12\nPerson A,\"One proposed solution to this paradox is the AdS/CFT correspondence, a conjectured duality between string theory in anti-de Sitter space and a conformal field theory on its boundary. Since the conformal field theory is unitary, it suggests that information must be preserved in black holes as well.\",14\nPerson B,\"Yes, but the challenge remains in understanding how exactly information escapes from a black hole. Hawking's paper, which we're discussing today, explores this using Euclidean path integrals. He suggests that black hole formation and evaporation can be viewed as a scattering process, with all measurements made at infinity.\",13\nPerson A,\"That's an intriguing approach. By considering the path integrals over metrics with trivial topology, Hawking argues that these are unitary and information-preserving. In contrast, path integrals over non-trivial topologies lead to correlation functions that decay to zero, implying that at late times, only the unitary path integrals contribute.\",15\nPerson B,\"It's a complex idea, but essentially, Hawking is suggesting that elementary quantum gravity interactions don't lose information or quantum coherence. This aligns with the notion that information is not lost in black holes, but rather, it might be encoded in subtle correlations in the radiation.\",12\nPerson A,\"It's fascinating to think about how these theoretical concepts could reshape our understanding of the universe. While the debate continues, Hawking's work has certainly paved the way for new insights into the nature of black holes and quantum gravity.\",10\nPerson B,\"Absolutely. It's a testament to the power of theoretical physics to challenge our assumptions and push the boundaries of what we know. I'm excited to see where future research will take us in resolving this paradox.\",9\nPerson A,\"Well, that's all the time we have for today's episode. Thank you for joining us on this journey through the cosmos. Until next time, keep questioning and exploring the wonders of the universe.\",10\n```",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "TextInput-qzzR3"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 625.5287779422649,
          "y": 863.7125320097903
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "File-JLkjD",
        "sourceHandle": "{dataType:File,id:File-JLkjD,name:data,output_types:[Data]}",
        "target": "SplitText-EIkgR",
        "targetHandle": "{fieldName:data_inputs,id:SplitText-EIkgR,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-EIkgR",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "File",
            "id": "File-JLkjD",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-File-JLkjD{dataType:File,id:File-JLkjD,name:data,output_types:[Data]}-SplitText-EIkgR{fieldName:data_inputs,id:SplitText-EIkgR,inputTypes:[Data],type:other}",
        "className": "",
        "animated": false
      },
      {
        "source": "MergeDataComponent-DPEsw",
        "sourceHandle": "{dataType:MergeDataComponent,id:MergeDataComponent-DPEsw,name:merged_data,output_types:[Data]}",
        "target": "ParseData-wLaBA",
        "targetHandle": "{fieldName:data,id:ParseData-wLaBA,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-wLaBA",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MergeDataComponent",
            "id": "MergeDataComponent-DPEsw",
            "name": "merged_data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MergeDataComponent-DPEsw{dataType:MergeDataComponent,id:MergeDataComponent-DPEsw,name:merged_data,output_types:[Data]}-ParseData-wLaBA{fieldName:data,id:ParseData-wLaBA,inputTypes:[Data],type:other}",
        "className": "",
        "animated": false
      },
      {
        "source": "SplitText-EIkgR",
        "sourceHandle": "{dataType:SplitText,id:SplitText-EIkgR,name:chunks,output_types:[Data]}",
        "target": "MergeDataComponent-DPEsw",
        "targetHandle": "{fieldName:data_inputs,id:MergeDataComponent-DPEsw,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "MergeDataComponent-DPEsw",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-EIkgR",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-SplitText-EIkgR{dataType:SplitText,id:SplitText-EIkgR,name:chunks,output_types:[Data]}-MergeDataComponent-DPEsw{fieldName:data_inputs,id:MergeDataComponent-DPEsw,inputTypes:[Data],type:other}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-wLaBA",
        "sourceHandle": "{dataType:ParseData,id:ParseData-wLaBA,name:text,output_types:[Message]}",
        "target": "Prompt-H1qCU",
        "targetHandle": "{fieldName:data,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "Prompt-H1qCU",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-wLaBA",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-wLaBA{dataType:ParseData,id:ParseData-wLaBA,name:text,output_types:[Message]}-Prompt-H1qCU{fieldName:data,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "TextInput-kZqKx",
        "sourceHandle": "{dataType:TextInput,id:TextInput-kZqKx,name:text,output_types:[Message]}",
        "target": "Prompt-H1qCU",
        "targetHandle": "{fieldName:number_of_speakers,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "number_of_speakers",
            "id": "Prompt-H1qCU",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-kZqKx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-kZqKx{dataType:TextInput,id:TextInput-kZqKx,name:text,output_types:[Message]}-Prompt-H1qCU{fieldName:number_of_speakers,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-H1qCU",
        "sourceHandle": "{dataType:Prompt,id:Prompt-H1qCU,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-SBKMK",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-SBKMK,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-SBKMK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-H1qCU",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-H1qCU{dataType:Prompt,id:Prompt-H1qCU,name:prompt,output_types:[Message]}-OpenAIModel-SBKMK{fieldName:input_value,id:OpenAIModel-SBKMK,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-SBKMK",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-SBKMK,name:text_output,output_types:[Message]}",
        "target": "MarkdownDataExtractorComponent-T063l",
        "targetHandle": "{fieldName:input_value,id:MarkdownDataExtractorComponent-T063l,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "MarkdownDataExtractorComponent-T063l",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-SBKMK",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-SBKMK{dataType:OpenAIModel,id:OpenAIModel-SBKMK,name:text_output,output_types:[Message]}-MarkdownDataExtractorComponent-T063l{fieldName:input_value,id:MarkdownDataExtractorComponent-T063l,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "MarkdownDataExtractorComponent-T063l",
        "sourceHandle": "{dataType:MarkdownDataExtractorComponent,id:MarkdownDataExtractorComponent-T063l,name:output,output_types:[Data]}",
        "target": "MultiSpeakerAudioGenerator-WmDnl",
        "targetHandle": "{fieldName:input_value,id:MultiSpeakerAudioGenerator-WmDnl,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "MultiSpeakerAudioGenerator-WmDnl",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MarkdownDataExtractorComponent",
            "id": "MarkdownDataExtractorComponent-T063l",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MarkdownDataExtractorComponent-T063l{dataType:MarkdownDataExtractorComponent,id:MarkdownDataExtractorComponent-T063l,name:output,output_types:[Data]}-MultiSpeakerAudioGenerator-WmDnl{fieldName:input_value,id:MultiSpeakerAudioGenerator-WmDnl,inputTypes:[Data],type:other}",
        "className": "",
        "animated": false
      },
      {
        "source": "TextInput-e5TZN",
        "sourceHandle": "{dataType:TextInput,id:TextInput-e5TZN,name:text,output_types:[Message]}",
        "target": "Prompt-H1qCU",
        "targetHandle": "{fieldName:additional_details,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "additional_details",
            "id": "Prompt-H1qCU",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-e5TZN",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-e5TZN{dataType:TextInput,id:TextInput-e5TZN,name:text,output_types:[Message]}-Prompt-H1qCU{fieldName:additional_details,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "TextInput-tsS3y",
        "sourceHandle": "{dataType:TextInput,id:TextInput-tsS3y,name:text,output_types:[Message]}",
        "target": "Prompt-H1qCU",
        "targetHandle": "{fieldName:output_format,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "output_format",
            "id": "Prompt-H1qCU",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-tsS3y",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-tsS3y{dataType:TextInput,id:TextInput-tsS3y,name:text,output_types:[Message]}-Prompt-H1qCU{fieldName:output_format,id:Prompt-H1qCU,inputTypes:[Message,Text],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "PackageInstallerComponent-qH7zC",
        "sourceHandle": "{dataType:PackageInstallerComponent,id:PackageInstallerComponent-qH7zC,name:install_output,output_types:[Message]}",
        "target": "PackageInstallerComponent-oywxA",
        "targetHandle": "{fieldName:pass_value,id:PackageInstallerComponent-oywxA,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "pass_value",
            "id": "PackageInstallerComponent-oywxA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "PackageInstallerComponent",
            "id": "PackageInstallerComponent-qH7zC",
            "name": "install_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-PackageInstallerComponent-qH7zC{dataType:PackageInstallerComponent,id:PackageInstallerComponent-qH7zC,name:install_output,output_types:[Message]}-PackageInstallerComponent-oywxA{fieldName:pass_value,id:PackageInstallerComponent-oywxA,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false
      },
      {
        "source": "MarkdownDataExtractorComponent-I4ZkA",
        "sourceHandle": "{dataType:MarkdownDataExtractorComponent,id:MarkdownDataExtractorComponent-I4ZkA,name:output,output_types:[Data]}",
        "target": "MultiSpeakerAudioGenerator-p2vl0",
        "targetHandle": "{fieldName:input_value,id:MultiSpeakerAudioGenerator-p2vl0,inputTypes:[Data],type:other}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "MultiSpeakerAudioGenerator-p2vl0",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MarkdownDataExtractorComponent",
            "id": "MarkdownDataExtractorComponent-I4ZkA",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MarkdownDataExtractorComponent-I4ZkA{dataType:MarkdownDataExtractorComponent,id:MarkdownDataExtractorComponent-I4ZkA,name:output,output_types:[Data]}-MultiSpeakerAudioGenerator-p2vl0{fieldName:input_value,id:MultiSpeakerAudioGenerator-p2vl0,inputTypes:[Data],type:other}",
        "animated": false,
        "className": ""
      },
      {
        "source": "TextInput-qzzR3",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qzzR3,name:text,output_types:[Message]}",
        "target": "MarkdownDataExtractorComponent-I4ZkA",
        "targetHandle": "{fieldName:input_value,id:MarkdownDataExtractorComponent-I4ZkA,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "MarkdownDataExtractorComponent-I4ZkA",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qzzR3",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qzzR3{dataType:TextInput,id:TextInput-qzzR3,name:text,output_types:[Message]}-MarkdownDataExtractorComponent-I4ZkA{fieldName:input_value,id:MarkdownDataExtractorComponent-I4ZkA,inputTypes:[Message],type:str}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 902.1583102712739,
      "y": 349.2119862336548,
      "zoom": 0.5216558248030585
    }
  },
  "description": "This Flow uses Data Objects to construct a Podcast Script and convert it to Audio using OpenAI Whisper TTS model.\nCheck the additional packages for installation before running the flow all once, you just need to run them in the first time you are going to install your packages.",
  "name": "Data to Speech (Langflow) (2)",
  "last_tested_version": "1.1.1",
  "endpoint_name": null,
  "is_component": false
}